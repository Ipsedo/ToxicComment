{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.read_data as read\n",
    "import data.transform_data as transform\n",
    "from numpy import concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_file_name = \"res/train.csv\"\n",
    "test_csv_file_name = \"res/test.csv\"\n",
    "test_label_csv_file_name = \"res/test_labels.csv\"\n",
    "submission_csv_file_name = \"res/sample_submission.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read.load_train_csv(train_csv_file_name).head(41000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id                                       comment_text  \\\n0      0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1      000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2      000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3      0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n4      0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n5      00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...   \n6      0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n7      00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n8      00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n9      00040093b2687caa  alignment on this subject and which are contra...   \n10     0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n11     00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...   \n12     0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n13     0006f16e4e9f292e  Before you start throwing accusations and warn...   \n14     00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n15     00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...   \n16     0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n17     000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n18     0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n19     0009eaea3325de8c  Don't mean to bother you \\n\\nI see that you're...   \n20     000b08c464718505  \"\\n\\n Regarding your recent edits \\n\\nOnce aga...   \n21     000bfd0867774845  \"\\nGood to know. About me, yeah, I'm studying ...   \n22     000c0dfd995809fa  \"\\n\\n Snowflakes are NOT always symmetrical! \\...   \n23     000c6a3f0cd3ba8e  \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...   \n24     000cfee90f50d471  \"\\n\\nRe-considering 1st paragraph edit?\\nI don...   \n25     000eefc67a2c930f  Radial symmetry \\n\\nSeveral now extinct lineag...   \n26     000f35deef84dc4a  There's no need to apologize. A Wikipedia arti...   \n27     000ffab30195c5e1  Yes, because the mother of the child in the ca...   \n28     0010307a3a50a353  \"\\nOk. But it will take a bit of work but I ca...   \n29     0010833a96e1f886  \"== A barnstar for you! ==\\n\\n  The Real Life ...   \n...                 ...                                                ...   \n40970  6d55e97897ffac27                             Because i killed them!   \n40971  6d5609cb05e3c733  Article name \\n\\n recently moved this article ...   \n40972  6d56b07c749e69fb  Thanks Lament for the restore.  I don't dare t...   \n40973  6d575bb7c7a424c9  \"\\n Your request at Files for upload \\n Hello,...   \n40974  6d575e3a7a820c42  \"\\n Your submission at AfC Shayan Modarres was...   \n40975  6d57be067dea348c  You probably noticed that the stl template can...   \n40976  6d5838b17603a0e9  Induced_gamma_emission:_Hafnium_controversy\\n\\...   \n40977  6d58a805bd630246  WikiProject Films November 2008 Newsletter\\nTh...   \n40978  6d59421cf19779e6  Thank you very much - image has been added to ...   \n40979  6d59909aa7f48bcc  GAR\\nThanks for the heads-up. Looking over the...   \n40980  6d5a1efd7217aa6e  Removed Links\\nMay I ask why you removed the l...   \n40981  6d5a9be006b128a3  This page was being redirected to Haidar Abbas...   \n40982  6d5c74d4b79dfde6  \"\\n  The BLPN thread begins with this from you...   \n40983  6d5d5e2834955dda  \"* This article says that he was the first His...   \n40984  6d5dec45c48dc41b  \"\\n—— '''[[user:Eagle 101|Eagle101]]'''Need he...   \n40985  6d5e7e4ee551694c  Vandalism of Mariah Carey article\\nPlease stop...   \n40986  6d5e9b8edfd4b91f  \"\\nReplied to you on Talk:The_Truth:_Gujarat_2...   \n40987  6d602816357e8e64  In 75 years....article...?????  In 75 years pe...   \n40988  6d603a3046efed28  Zencv, my edit from a day ago that you referen...   \n40989  6d60cced80491ece  \"\\nI've had it, you ignorant fool. If it's cal...   \n40990  6d61d6526a69acb3  They are perfectly civil - they have no hidden...   \n40991  6d62695845ea12ef  The suggestion is to replace this dab page wit...   \n40992  6d62dd9285b068bd  Somebody deleted my factoid that one supertank...   \n40993  6d632ee360b4b88d  Picture of the band \\n\\nWell, Kjoonlee, that's...   \n40994  6d6349752e253a70  Unspecified source for Image:Zeldaor.PNG\\n\\nTh...   \n40995  6d63859d636a6353  \"\\n\\nEarthworms are nice!\\nArticle claims he g...   \n40996  6d638940d3fa44ed  Sherlock, as it states earlier in the article,...   \n40997  6d640c887a761922  Unlocking Herne Hill and the Kent route to the...   \n40998  6d64d4b11528375d  \", 29 March 2009 (UTC)\\n\\n(not so random un-in...   \n40999  6d654a0b483c892c  \"Also, I want to apologize for my extreme beha...   \n\n       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0          0             0        0       0       0              0  \n1          0             0        0       0       0              0  \n2          0             0        0       0       0              0  \n3          0             0        0       0       0              0  \n4          0             0        0       0       0              0  \n5          0             0        0       0       0              0  \n6          1             1        1       0       1              0  \n7          0             0        0       0       0              0  \n8          0             0        0       0       0              0  \n9          0             0        0       0       0              0  \n10         0             0        0       0       0              0  \n11         0             0        0       0       0              0  \n12         1             0        0       0       0              0  \n13         0             0        0       0       0              0  \n14         0             0        0       0       0              0  \n15         0             0        0       0       0              0  \n16         1             0        0       0       0              0  \n17         0             0        0       0       0              0  \n18         0             0        0       0       0              0  \n19         0             0        0       0       0              0  \n20         0             0        0       0       0              0  \n21         0             0        0       0       0              0  \n22         0             0        0       0       0              0  \n23         0             0        0       0       0              0  \n24         0             0        0       0       0              0  \n25         0             0        0       0       0              0  \n26         0             0        0       0       0              0  \n27         0             0        0       0       0              0  \n28         0             0        0       0       0              0  \n29         0             0        0       0       0              0  \n...      ...           ...      ...     ...     ...            ...  \n40970      1             0        0       0       0              0  \n40971      0             0        0       0       0              0  \n40972      0             0        0       0       0              0  \n40973      0             0        0       0       0              0  \n40974      0             0        0       0       0              0  \n40975      0             0        0       0       0              0  \n40976      0             0        0       0       0              0  \n40977      0             0        0       0       0              0  \n40978      0             0        0       0       0              0  \n40979      0             0        0       0       0              0  \n40980      0             0        0       0       0              0  \n40981      0             0        0       0       0              0  \n40982      0             0        0       0       0              0  \n40983      0             0        0       0       0              0  \n40984      0             0        0       0       0              0  \n40985      0             0        0       0       0              0  \n40986      0             0        0       0       0              0  \n40987      0             0        0       0       0              0  \n40988      0             0        0       0       0              0  \n40989      1             0        0       0       0              0  \n40990      1             0        0       0       1              0  \n40991      0             0        0       0       0              0  \n40992      0             0        0       0       0              0  \n40993      0             0        0       0       0              0  \n40994      0             0        0       0       0              0  \n40995      0             0        0       0       0              0  \n40996      0             0        0       0       0              0  \n40997      0             0        0       0       0              0  \n40998      0             0        0       0       0              0  \n40999      0             0        0       0       0              0  \n\n[41000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               object\ncomment_text     object\ntoxic             int64\nsevere_toxic      int64\nobscene           int64\nthreat            int64\ninsult            int64\nidentity_hate     int64\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_train = 40000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:limit_train, :2].values\n",
    "Y_train = df_train.iloc[:limit_train, 2:].values\n",
    "\n",
    "X_test = df_train.iloc[limit_train:, :2].values\n",
    "Y_test = df_train.iloc[limit_train:, 2:].values\n",
    "\n",
    "X_train = transform.split_comment(X_train)\n",
    "X_test = transform.split_comment(X_test)\n",
    "\n",
    "count, vocab = transform.mk_vocab(X_train + X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11154\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0000997932d777bf', array(['explanation', 'why', 'the', 'edits', 'made', 'under', 'my',\n       'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted',\n       'they', 'weren', 't', 'vandalisms', 'just', 'closure', 'on',\n       'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls',\n       'fac', 'and', 'please', 'don', 't', 'remove', 'the', 'template',\n       'from', 'the', 'talk', 'page', 'since', 'i', 'm', 'retired', 'now',\n       '89', '205', '38', '27'], dtype='<U11'))\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident_train, X_train = transform.pass_data_to_word_idx(X_train, vocab, count)\n",
    "ident_test, X_test = transform.pass_data_to_word_idx(X_test, vocab, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 16, 33,\n        3, 34, 35,  3, 36, 37, 38, 24, 39, 40, 41, 42, 43, 44, 45])\n array([46, 47, 48, 49, 50, 51, 24, 39, 52, 53, 54, 55, 36, 56, 57, 58, 59,\n       60, 61])\n array([62, 63, 24, 39, 64, 65, 66, 67, 68, 69, 70, 71, 18, 72, 49, 73, 74,\n       75, 76, 77, 78, 30, 79, 67, 80, 81,  4, 82, 83,  7, 36, 37, 47, 84,\n       67, 85, 86, 87,  3, 88, 89,  3, 90, 91])\n ...\n array([6741,   30,    3, 5566, 3793,   67,    3, 3114,  130,  112,  103,\n        718,  531,  532,  724,  552, 6741,   30,    3, 5566, 3793,   67,\n          3, 3114,  822,   36])\n array([ 2120,  2454,  4244,    61,    65,   114,  6074,  2559, 10164,\n         404,  8703,    74,    67,  4178,   269,    81,   106,  2586,\n        1569,    83,  1145,   203,    74,  6108,    26,  1240,   502,\n           3,    74,   162,  3500,    49,  1569,    83,  1145,   250,\n         627,  9444,  1119,  2160,   105,    86,     3,  1024,    83,\n        2428,  9445,   998,    83,    49,  1569,    83,  1145,    74,\n        6305,    67,     3,  1735,   105,    86,  1829,     3,  5930,\n        1041,    83,     3,  1040,    20,     3,  1145,  5677,     3,\n        1735,  1041,    26,     3,    83,    49,  1569,    83,  1145,\n         528,    35,     3,  1474,    74,  4293,  2107,  1145,   115,\n         214,    67,  1310,  1921,  1014, 10459,     3,  1014,    83,\n         106,    74,  5286,   226,   741,  1079,    30,  3228,   112,\n         998,  4624,    71,  1921,     3,  3976,   601,   813,    72,\n           3,  1024,    83,   998,    83,  9445,    74,  6305,    67,\n           3,  2789,  1041,    20,     3,     3,  5118,   601,   813,\n          72,     3,  1041,   250,   126,    20,   226,    74,  6305,\n          67,  5677,     3,  1041,   250,    72,    20,    72,  1108,\n         106,  1041,  5729,    99,  1906,    74,  1005,     3,  5589,\n        8096,    26,     3,  4227,    83,     3,    74,   268,    72,\n         226,  1079,   128,    65,   998,   198,   226,   741,    30,\n        3228,   112,   998,   117,   645,    83,   106, 10146,  5589,\n          30,  1079,   115,  1375,    81,    21,  5783,    83,  1443,\n          38,     3,  1014,    74,  5286,   106,  1079,   998,  1850,\n         106, 10169,   998,   499,  1310,  2017,   300,   117,  1175,\n           3,  5767,    83,     3,    54,     3,  1061,    35,    70,\n          38,     3,  2492,    83,     3,  1079,   250,     3,  1153,\n          74,  2886,   117,   226,   613,    49,   206,    21,  3993,\n          67,   408,     3,    83,   170,  1133,    74,    56,   854])\n array([ 230,   24,  135,   67,  631,  133,    7, 1982,  360,   26,    3,\n        275,   37,   24,   18,  890,   70, 8415,  863,   30,   24,   92,\n        103,   64, 8872, 2202,   24,  189,   26, 2486,  376,  106, 2113,\n       8302])]\n[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 16, 33,\n        3, 34, 35,  3, 36, 37, 38, 24, 39, 40, 41, 42, 43, 44, 45])\n array([46, 47, 48, 49, 50, 51, 24, 39, 52, 53, 54, 55, 36, 56, 57, 58, 59,\n       60, 61])\n array([62, 63, 24, 39, 64, 65, 66, 67, 68, 69, 70, 71, 18, 72, 49, 73, 74,\n       75, 76, 77, 78, 30, 79, 67, 80, 81,  4, 82, 83,  7, 36, 37, 47, 84,\n       67, 85, 86, 87,  3, 88, 89,  3, 90, 91])\n ...\n array([ 899, 1944,   30,  899,   67,  153,  280,  130,  133,  170,  252,\n         24,  613,  130,  376,    3, 1649,   30, 4390,   67, 3795,  489,\n        115,   21,  245,   72,  130, 1012,  247, 2916,    3, 3087, 3088,\n         83,  153, 4391,  455,   67,   68,  106,   37,  455,   67,  186,\n        106, 1541,  173, 3094,   83,  134,   24,  613,  130, 3140,  504,\n        489,   30,  224,  106, 2675,   31, 2523,  170, 2186,   20,  411,\n        245,  234,  706, 3081,   49,  177, 2606, 2713,  170,    8,   30,\n          3,  122,   99,  130,  113, 1205,  885,  231,  153,  276,  277,\n         80,   20,  105,  277,  170,  589,   20,   49,   37,   30,  259,\n       1649, 4822,  166,    3,  589,  176,  899, 4156, 4318, 2689,   20,\n       6160, 5191, 5192,  161,    3,  846,  117,    3, 3160, 1909,   31,\n        124,   65,   33,    3,  180, 4156,  902,  129, 2973,   70,   20,\n          3,   36,   37,   55])\n array([  70,   71,   67,  138,   72,  130, 1411,  131, 1474,  491,   67,\n        124,   89, 4406,  133, 1540,  161,   24,  131,  519,  247,  187,\n        334, 2851,  117,    7,    4,   30,  137,   80,  138,   31])\n array([ 7081,   269,    83,  6859,  1944,    54,   170,  4327,  2221,\n          83,   153,    71,  1457,  2192,    30,   874,    30,  4449,\n          54,   170,  3423,  1678,   133,  6859,   972, 10117,  1698,\n          24,   182,  2207,    99,   130,   456,   492,   106,    26,\n           3,  1788,  1482,  4332,   173,    30,   969,    21,   166,\n           3,    68,    69,   148,  5599,    55])]\n"
     ]
    }
   ],
   "source": [
    "max_len = transform.get_max_len_sent(concatenate((X_train, X_test), axis=0))\n",
    "print(max_len)\n",
    "print(concatenate((X_train, X_test), axis=0))\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transform.pad_sentences(X_train, max_len, vocab[transform.padding])\n",
    "X_test = transform.pad_sentences(X_test, max_len, vocab[transform.padding])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3. ...   0.   0.   0.]\n [ 46.  47.  48. ...   0.   0.   0.]\n [ 62.  63.  24. ...   0.   0.   0.]\n ...\n [170. 171.  67. ...   0.   0.   0.]\n [179.  99.   3. ...   0.   0.   0.]\n [ 20.  49. 214. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1400)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0]\n(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[0])\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.conv_model import ConvModel\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from utils.cuda import use_cuda\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : loss = 0.123167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxic': 0.8511110389540106, 'severe_toxic': 0.9004040404040404, 'obscene': 0.8604491079235735, 'threat': 0.9585422935473086, 'insult': 0.8737955750123394, 'identity_hate': 0.8753976311336719}\n0.8866166144958242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : loss = 0.087995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxic': 0.92222186143672, 'severe_toxic': 0.9615151515151515, 'obscene': 0.9302710647243773, 'threat': 0.9689067201604815, 'insult': 0.9443979484538294, 'identity_hate': 0.9275126903553299}\n0.9424709061076483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : loss = 0.064401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxic': 0.9522356073643536, 'severe_toxic': 0.9739393939393939, 'obscene': 0.9657308701233466, 'threat': 0.9725844199264461, 'insult': 0.9649134101590163, 'identity_hate': 0.9442301184433164}\n0.9622723033259789\n"
     ]
    }
   ],
   "source": [
    "model = ConvModel(len(vocab), max_len)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "if use_cuda():\n",
    "    model.cuda()\n",
    "    loss_fn.cuda()\n",
    "\n",
    "opt = th.optim.Adagrad(model.parameters(), lr=5e-3)\n",
    "\n",
    "nb_epoch = 3\n",
    "\n",
    "batch_size = 32\n",
    "nb_batch = int(X_train.shape[0] / batch_size)\n",
    "\n",
    "for e in range(nb_epoch):\n",
    "    model.train()\n",
    "    \n",
    "    if use_cuda():\n",
    "        model.cuda()\n",
    "        \n",
    "    sum_loss = 0\n",
    "    nb_sent = 0\n",
    "    \n",
    "    for i in range(nb_batch):\n",
    "        i_min = batch_size * i\n",
    "        i_max = batch_size * (i + 1) if batch_size * (i + 1) < X_train.shape[0] else X_train.shape[0]\n",
    "                \n",
    "        x = th.Tensor(X_train[i_min:i_max]).long()\n",
    "        y = th.Tensor(Y_train[i_min:i_max])\n",
    "        if use_cuda():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        nb_sent += 1\n",
    "    \n",
    "    sum_loss /= nb_sent\n",
    "    \n",
    "    print(\"Epoch %d : loss = %f\" % (e, sum_loss))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    model.cpu()\n",
    "    \n",
    "    x_test = th.Tensor(X_test).long()\n",
    "    y_test = th.Tensor(Y_test)\n",
    "    res = th.zeros(y_test.size())\n",
    "    \n",
    "    batch_size_test = 32\n",
    "    nb_batch_test = int(x_test.size(0) / batch_size_test)\n",
    "    \n",
    "    for i in range(nb_batch_test):\n",
    "        i_min = batch_size_test * i\n",
    "        i_max = batch_size_test * (i + 1) if batch_size_test * (i + 1) < x_test.size(0) else x_test.size(0)\n",
    "        \n",
    "        x = x_test[i_min:i_max]\n",
    "        y = y_test[i_min:i_max]\n",
    "        \n",
    "        out_test = model(x)\n",
    "        # diff = th.abs(y - out_test)\n",
    "        res[i_min:i_max] = out_test\n",
    "    \n",
    "    y_test = y_test.detach().numpy()\n",
    "    res = res.detach().numpy()\n",
    "    roc_auc_scores = {\n",
    "        \"toxic\": roc_auc_score(y_test[:, 0], res[:, 0]),\n",
    "        \"severe_toxic\": roc_auc_score(y_test[:, 1], res[:, 1]),\n",
    "        \"obscene\": roc_auc_score(y_test[:, 2], res[:, 2]),\n",
    "        \"threat\": roc_auc_score(y_test[:, 3], res[:, 3]),\n",
    "        \"insult\": roc_auc_score(y_test[:, 4], res[:, 4]),\n",
    "        \"identity_hate\": roc_auc_score(y_test[:, 5], res[:, 5])\n",
    "    }\n",
    "    \n",
    "    print(roc_auc_scores)\n",
    "    print(sum([v for _, v in roc_auc_scores.items()]) / 6)\n",
    "    \"\"\"\n",
    "    diff = res.mean(dim=0)\n",
    "    differences = {\n",
    "        \"toxic\": diff[0].item(),\n",
    "        \"severe_toxic\": diff[1].item(),\n",
    "        \"obscene\": diff[2].item(),\n",
    "        \"threat\": diff[3].item(),\n",
    "        \"insult\": diff[4].item(),\n",
    "        \"identity_hate\": diff[5].item()}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvModel(\n  (emb): Embedding(25385, 16)\n  (seq1): Sequential(\n    (0): Conv1d(16, 24, kernel_size=(5,), stride=(1,))\n    (1): ReLU()\n    (2): Conv1d(24, 32, kernel_size=(3,), stride=(1,))\n    (3): ReLU()\n    (4): MaxPool1d(kernel_size=1394, stride=1394, padding=0, dilation=1, ceil_mode=False)\n  )\n  (seq2): Sequential(\n    (0): Linear(in_features=32, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=6, bias=True)\n    (3): Sigmoid()\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Save model, loss function, optimizer, vocabulary and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = model.cpu()\n",
    "saved_loss = loss_fn.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime.now()\n",
    "saved_identity = \"_lowercase_\" + dt.strftime(\"%Hh_%Mm_%Ss_%d_%m_%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"saved/model\" + saved_identity + \".p\", \"wb\"))\n",
    "pickle.dump(loss_fn, open(\"saved/loss_fn\" + saved_identity + \".p\", \"wb\"))\n",
    "pickle.dump(opt, open(\"saved/opt\" + saved_identity + \".p\", \"wb\"))\n",
    "pickle.dump(vocab, open(\"saved/vocab\" + saved_identity + \".p\", \"wb\"))\n",
    "pickle.dump(count, open(\"saved/count\" + saved_identity + \".p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
